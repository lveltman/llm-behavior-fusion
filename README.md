# Behavioral Twin LLM Fusion ‚Äî –ì–∏–±–∫–∞—è –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è LLM —á–µ—Ä–µ–∑ Q-Former

> **Beyond PPlug**: We replace simple weighted averaging with a **Q-Former cross-attention module** to better model user behavior for LLM personalization.

## üîç –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç

–ü—Ä–æ–µ–∫—Ç —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç **BehavioralTwin** ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ LLM, –∫–æ—Ç–æ—Ä–∞—è:
- –ö–æ–¥–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ **–∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–π BGE —ç–Ω–∫–æ–¥–µ—Ä**
- –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∏ –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ **Q-Former** (learnable queries + –∫—Ä–æ—Å—Å-–≤–Ω–∏–º–∞–Ω–∏–µ)
- –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –≤ **Flan-T5-XXL / Qwen** –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è —Å–∞–º–æ–π LLM

**–†–µ–∑—É–ª—å—Ç–∞—Ç**: **+5.05% accuracy** –Ω–∞ LaMP-1 –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å PPlug (0.8997 vs 0.8492).

# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è: Behavioral Twin LLM Fusion

**Behavioral Twin** ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –≥–ª—É–±–æ–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM), —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—â–∏–π –∏—Å—Ç–æ—Ä–∏—é –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å.
–ü—Ä–æ–µ–∫—Ç —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã—Ö LLM –∫ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ–∑ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ LLM.

---

## 1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞

–í –æ—Å–Ω–æ–≤–µ —Å–∏—Å—Ç–µ–º—ã –ª–µ–∂–∏—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—è **Latent Context Bottleneck**. –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Å—ã—Ä—ã–µ —Ç–µ–∫—Å—Ç—ã –∏—Å—Ç–æ—Ä–∏–∏ –≤ LLM (—á—Ç–æ –≤–µ–¥–µ—Ç –∫ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–º—É —Ä–æ—Å—Ç—É –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏), –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å ¬´–±—É—Ç—ã–ª–æ—á–Ω—ã–º –≥–æ—Ä–ª—ã—à–∫–æ–º¬ª, –∫–æ—Ç–æ—Ä–∞—è —Å–∂–∏–º–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.


## üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
[User History] ‚Üí Behavioral Encoder ‚Üí [P√ó768]
                                  ‚Üò
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ   Q-FORMER    ‚îÇ ‚Üê 8 –æ–±—É—á–∞–µ–º—ã—Ö queries
                                    ‚îÇ ‚Ä¢ Cross-att (history) ‚îÇ
                                    ‚îÇ ‚Ä¢ Cross-att (input)   ‚îÇ
                                    ‚îÇ ‚Ä¢ Self-att (queries)  ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üí [Q√óH]
                                  ‚Üó
[Current Query] ‚Üí Input Encoder  ‚Üí [1√ó768]

[Q√óH] ‚Üí Proj ‚Üí Prefix ‚Üí LLM ‚Üí [1] or [2]
```

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:

1. **Behavioral Encoder (Frozen ‚ùÑÔ∏è)**:
* **Backbone**: `BAAI/bge-base-en-v1.5`.
* **–†–æ–ª—å**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è.
* **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å**: –†–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ `inference-only`, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞ –¥–∏—Å–∫–µ/–≤ –ë–î (–∏–¥–µ—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è).


2. **Input Encoder (Partially Tuned üî•)**:
* **Backbone**: `BAAI/bge-base-en-v1.5`.
* **–ù–∞—Å—Ç—Ä–æ–π–∫–∞**: Fine-tuning 4-—Ö –≤–µ—Ä—Ö–Ω–∏—Ö —Å–ª–æ–µ–≤.
* **–†–æ–ª—å**: –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ Cross-Attention –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ Q-Former (Alignment).


3. **Q-Former (Learnable üî•)**:
* **–ú–µ—Ö–∞–Ω–∏–∫–∞**: 8 –æ–±—É—á–∞–µ–º—ã—Ö –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (queries).
* **–ü—Ä–æ—Ü–µ—Å—Å**:
    *   –°–æ–¥–µ—Ä–∂–∏—Ç –æ–±—É—á–∞–µ–º—ã–µ `query_tokens` —Ñ–æ—Ä–º—ã `[1, num_queries, hidden_size]`, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å—à–∏—Ä—è—é—Ç—Å—è –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.
    *   –í—ã–ø–æ–ª–Ω—è–µ—Ç **–∫—Ä–æ—Å—Å-–≤–Ω–∏–º–∞–Ω–∏–µ** –º–µ–∂–¥—É `query_tokens` –∏ `behavioral_embs` (–≤–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ—Å–ª–µ BehavioralEncoder).
    *   –í—ã–ø–æ–ª–Ω—è–µ—Ç **–∫—Ä–æ—Å—Å-–≤–Ω–∏–º–∞–Ω–∏–µ** –º–µ–∂–¥—É –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ `query_tokens` –∏ `input_embs` (–≤–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ—Å–ª–µ SimpleTextEncoder).
    *   –ü—Ä–∏–º–µ–Ω—è–µ—Ç **—Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏–µ** –º–µ–∂–¥—É `query_tokens` –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
* **–ò—Ç–æ–≥**: –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ —Ç–µ–∫—É—â–µ–º—É –º–æ–º–µ–Ω—Ç—É.


4. **Fusion Model (Prefix-Tuning)**:
* **Backbone**: `Flan-T5-XXL` (Encoder-Decoder).
* **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**: –°–ø—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã Q-Former –ø–æ–¥–∞—é—Ç—Å—è –∫–∞–∫ **Soft Prompts** –≤ –Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. LLM –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏—Ö –∫–∞–∫ 8 –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç—å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

## 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ SOTA

–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø—Ä–æ–≤–æ–¥–∏–ª–∏—Å—å –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ **LaMP-1** (Personalized Citation Identification).

| –ú–æ–¥–µ–ª—å | Accuracy | –ü—Ä–∏—Ä–æ—Å—Ç |
| --- | --- | --- |
| **PPlug (Baseline)** | 0.8492 | - |
| **Behavioral Twin (Ours)** | **0.8997** | **+5.05%** |

**–ê–Ω–∞–ª–∏–∑**: –ú–æ–¥–µ–ª—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –≥–ª—É–±–æ–∫–æ–º—É —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É –ø–æ–∏—Å–∫—É. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç PPlug, Behavioral Twin —É—Å–ø–µ—à–Ω–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∞–∂–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ª–µ–∫—Å–∏—á–µ—Å–∫–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (keyword overlap) –º–µ–∂–¥—É –∏—Å—Ç–æ—Ä–∏–µ–π –∏ –∑–∞–ø—Ä–æ—Å–æ–º.

–†–∞–∑–Ω–∏—Ü–∞ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ PPlug:

| –ú–µ—Ç—Ä–∏–∫–∞ | –†–∞–∑–Ω–∏—Ü–∞ (Abs. Delta) |
|----------|-----------------------|
| Accuracy | +5.046%               |
| Precision| +5.026%               |
| Recall   | +5.051%               |

‚Üí –£–ª—É—á—à–µ–Ω–∏–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –∑–∞ —Å—á—ë—Ç **–±–æ–ª–µ–µ –±–æ–≥–∞—Ç–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ Q-Former**.

---

## 5. –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ —Ä–∞–∑–≤–∏—Ç–∏—è (Future Work)

### 5.1 –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è –ø–∞–º—è—Ç—å (Long-Term Memory)

–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ —Ä–∞–∑–º–µ—Ä–æ–º –±–∞—Ç—á–∞. –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (**FAISS / ChromaDB**).

* **–ú–µ—Ç–æ–¥**: –°–Ω–∞—á–∞–ª–∞ –∏–∑ –ë–î –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è N –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å—Ç–∞—Ç–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ç–µ–º –ø–æ–¥–∞—é—Ç—Å—è –≤ Q-Former. –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≥–ª—É–±–∏–Ω–æ–π –≤ —Ç—ã—Å—è—á–∏ —Å–æ–±—ã—Ç–∏–π.

### 5.2 –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã

–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ–Ω—è—Ç–∏—è ¬´–ø–æ–≤–µ–¥–µ–Ω–∏–µ¬ª –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Ç–µ–∫—Å—Ç–∞.

* **–ú–µ—Ç–æ–¥**: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–ª–æ—è –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–æ–ª-–≤–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é, —Ä–µ–π—Ç–∏–Ω–≥ –∏ —Ç–¥). Q-Former –±—É–¥–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–∏ —Å–∏–≥–Ω–∞–ª—ã —á–µ—Ä–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ Cross-Attention.

### 5.3 Adaptive queries

* **–ú–µ—Ç–æ–¥**: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ queries –≤ Q-Former. –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 1-2 –≤–µ–∫—Ç–æ—Ä–∞, –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö ‚Äî —Ä–∞—Å—à–∏—Ä—è—Ç—å ¬´–≥–æ—Ä–ª—ã—à–∫–æ¬ª –¥–æ 16.


## ‚öôÔ∏è –ó–∞–ø—É—Å–∫

```bash
accelerate launch --config_file config/ds_config.yaml train.py
```

### –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã (`train.py`)
```python
mode = "sequential"  # –æ–±—É—á–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ –∑–∞–¥–∞—á–∞–º (LaMP-1, LaMP-2, ...)
mode = "joint"       # –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
mode = "eval_only"   # —Ç–æ–ª—å–∫–æ –æ—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫

# –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è:
resume_from = "saved/checkpoints/your_model.pt"

# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (LaMP-1):
lr = 1e-4
warmup_ratio = 0.05
num_queries = 8
batch_size = 4  # –¥–ª—è Flan-T5-XXL
```

## üìä –î–∞–Ω–Ω—ã–µ

- **–û—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Å–µ—Ç**: [LaMP Benchmark](https://lamp-benchmark.github.io/download)
- **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**: [Research Papers Dataset (Kaggle)](https://www.kaggle.com/datasets/nechbamohammed/research-papers-dataset)

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–¥–∞

```
‚îú‚îÄ‚îÄ model.py             # BehavioralTwin, QFormer, FusionModel
‚îú‚îÄ‚îÄ pplug.py             # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è baseline (PPlug)
‚îú‚îÄ‚îÄ dataset/             # LaMPDataset —Å author-disjoint split
‚îú‚îÄ‚îÄ trainers/            # TaskSequentialTrainer, ModelEvaluator
‚îî‚îÄ‚îÄ train.py             # –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
```
