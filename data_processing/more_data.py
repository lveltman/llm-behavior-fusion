import pandas as pd
import numpy as np
import re
import ast
import random
import json
from tqdm import tqdm
from collections import Counter

# -------------------------------------------------
# –ü–∞—Ä—Å–µ—Ä—ã –∞–≤—Ç–æ—Ä–æ–≤
# -------------------------------------------------

def parse_authors_new_format(authors_str):
    """–î–ª—è —Ñ–æ—Ä–º–∞—Ç–∞: "['Name1', 'Name2']" ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç set"""
    if not isinstance(authors_str, str):
        return set()
    authors_str = authors_str.strip()
    if not (authors_str.startswith("[") and authors_str.endswith("]")):
        return set()
    try:
        lst = ast.literal_eval(authors_str)
        if isinstance(lst, list):
            return {str(x).strip() for x in lst if x and str(x).strip() != '...'}
    except:
        pass
    return set()

def parse_authors_as_list(authors_str):
    """–î–ª—è —Ñ–æ—Ä–º–∞—Ç–∞: "['Name1', 'Name2']" ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞"""
    if not isinstance(authors_str, str):
        return []
    authors_str = authors_str.strip()
    if authors_str.startswith("[") and authors_str.endswith("]"):
        try:
            lst = ast.literal_eval(authors_str)
            if isinstance(lst, list):
                return [str(x).strip() for x in lst if x and str(x).strip() != '...']
        except:
            pass
    return []


# -------------------------------------------------
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
# -------------------------------------------------

def build_dataset(df, max_examples=1_000_000):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LaMP-1 –¥–∞—Ç–∞—Å–µ—Ç.
    –†–µ–∂–∏–º: —Ç–æ–ª—å–∫–æ 'new' (–∫–æ–ª–æ–Ω–∫–∞ 'authors').
    –ë–µ—Ä—ë—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ –∏ –¥–æ 3 –µ–≥–æ —Å—Ç–∞—Ç–µ–π –≤ behavior_profile.
    """
    df = df.copy()
    
    if 'authors' not in df.columns:
        raise ValueError("–¢—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∞ 'authors'")
    
    print("–ü–∞—Ä—Å–∏–Ω–≥ –∞–≤—Ç–æ—Ä–æ–≤...")
    df['author_set'] = df['authors'].apply(parse_authors_new_format)
    df['author_list'] = df['authors'].apply(parse_authors_as_list)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∞–≤—Ç–æ—Ä–æ–≤
    df = df[df['author_set'].apply(len) > 0].copy()
    df = df[df['author_list'].apply(len) > 0].copy()
    
    # –°—Ç—Ä–æ–∏–º –º–∞–ø–ø–∏–Ω–≥: –∞–≤—Ç–æ—Ä ‚Üí —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ –µ–≥–æ —Å—Ç–∞—Ç–µ–π
    author_to_papers = {}
    for idx, author_set in zip(df.index, df['author_set']):
        for author in author_set:
            author_to_papers.setdefault(author, []).append(idx)
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç—å–∏, –≥–¥–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞–≤—Ç–æ—Ä –∏–º–µ–µ—Ç ‚â•2 —Å—Ç–∞—Ç—å–∏
    all_authors = [a for authors in df['author_set'] for a in authors]
    author_counts = Counter(all_authors)
    multi_authors = {a for a, cnt in author_counts.items() if cnt >= 2}
    df = df[df['author_set'].apply(lambda s: bool(s & multi_authors))].copy()
    print(f"–û—Å—Ç–∞–ª–æ—Å—å —Å—Ç–∞—Ç–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(df)}")

    # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –º–∞—Å—Å–∏–≤—ã (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    titles = df['title'].fillna("").astype(str).values
    abstracts = df['abstract'].fillna("").astype(str).values
    ids = df['id'].astype(str).values
    author_sets = df['author_set'].values
    author_lists = df['author_list'].values
    
    indices = df.index.tolist()
    n = len(df)
    all_indices_set = set(indices)
    index_to_pos = {idx: i for i, idx in enumerate(indices)}
    
    # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–∏–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è positive/negative (–≤—Å–µ —Å—Ç–∞—Ç—å–∏ —Å–æ–∞–≤—Ç–æ—Ä–æ–≤ —Ç–µ–∫—É—â–µ–π —Å—Ç–∞—Ç—å–∏)
    author_papers_list = []
    for author_set in df['author_set']:
        papers = set()
        for author in author_set:
            papers.update(author_to_papers.get(author, []))
        author_papers_list.append(papers)
    
    results = []
    print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∞–≤—Ç–æ—Ä, –¥–æ 3 behavior-—Å—Ç–∞—Ç–µ–π)...")
    
    for i in tqdm(range(n), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞"):
        idx = indices[i]
        title = titles[i]
        if not title.strip():
            continue

        author_papers = author_papers_list[i]
        other_author_papers = author_papers - {idx}
        if not other_author_papers:
            continue

        # Positive: —Å–ª—É—á–∞–π–Ω–∞—è —Å—Ç–∞—Ç—å—è –æ—Ç —Ç–æ–≥–æ –∂–µ –∞–≤—Ç–æ—Ä–∞
        pos_paper_idx = random.choice(list(other_author_papers))
        pos_pos = index_to_pos[pos_paper_idx]
        pos_title = titles[pos_pos]
        if not pos_title.strip():
            continue

        # Negative: —Å–ª—É—á–∞–π–Ω–∞—è —Å—Ç–∞—Ç—å—è –æ—Ç –¥—Ä—É–≥–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
        non_author_papers = list(all_indices_set - author_papers)
        if not non_author_papers:
            continue
        neg_paper_idx = random.choice(non_author_papers)
        neg_pos = index_to_pos[neg_paper_idx]
        neg_title = titles[neg_pos]
        if not neg_title.strip():
            continue

        # –°–ª—É—á–∞–π–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤
        if random.random() < 0.5:
            ref1, ref2 = neg_title, pos_title
            answer = "[2]"
        else:
            ref1, ref2 = pos_title, neg_title
            answer = "[1]"

        # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∞–≤—Ç–æ—Ä
        first_author = author_lists[i][0]
        input_text = (
            f'For author {first_author} who has written the paper with the title "{title}", '
            f'which reference is related? Just answer with [1] or [2] without explanation. '
            f'[1]: "{ref1}" [2]: "{ref2}"'
        )

        # Behavior profile: –¥–æ 3 —Å—Ç–∞—Ç–µ–π –ø–µ—Ä–≤–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ (–∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π)
        behavior_texts = []
        author_papers_all = author_to_papers.get(first_author, [])
        relevant_papers = [pid for pid in author_papers_all if pid != idx]
        k = min(3, len(relevant_papers))
        if k > 0:
            sampled_papers = random.sample(relevant_papers, k)
            for paper_idx in sampled_papers:
                p_pos = index_to_pos[paper_idx]
                t = titles[p_pos]
                a = abstracts[p_pos]
                if t.strip():
                    behavior_texts.append(f'TITLE: "{t}" ABSTRACT: {a}')

        results.append({
            "task": "LaMP_1",
            "id": ids[i],
            "input_text": input_text,
            "output_text": answer,
            "behavior_profile_text": behavior_texts
        })

        if len(results) >= max_examples:
            break

    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(results)} –ø—Ä–∏–º–µ—Ä–æ–≤.")
    return results



if __name__ == "__main__":
    filepath = "/home/veltman.lina/.cache/kagglehub/datasets/nechbamohammed/research-papers-dataset/versions/1/dblp-v10.csv"
    
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = pd.read_csv(filepath, usecols=['id', 'title', 'abstract', 'authors'])
    
    dataset = build_dataset(df, max_examples=500_000)
    
    output_path = "../data/lamp1_author_relevance_first_author.json"
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ {output_path}...")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    
    print("–ì–æ—Ç–æ–≤–æ! üéâ")